# GuÃ­a de ImplementaciÃ³n y SoluciÃ³n de Problemas - Azure AKS# GuÃ­a de Despliegue - Azure Kubernetes Service (AKS)



## ğŸ“‹ Contexto del Proyecto## ğŸ“‹ Requisitos Previos



Esta guÃ­a documenta la **implementaciÃ³n y soluciÃ³n de problemas** realizada en un cluster de Azure Kubernetes Service (AKS) ya existente que presentaba pods en estado **CrashLoopBackOff** debido a errores de configuraciÃ³n.### Cuenta de Azure

- **SuscripciÃ³n activa** de Azure (Azure for Students o Pay-As-You-Go)

### InformaciÃ³n del Cluster- **Azure CLI** instalado localmente O usar **Azure Cloud Shell**

- **Cluster AKS:** `k8s-azure`- **kubectl** instalado (viene preinstalado en Cloud Shell)

- **Resource Group:** `rg-k8s-azure`

- **RegiÃ³n:** `eastus2`### Recursos del Proyecto

- **Azure Container Registry:** `acrk8sazure1762621825.azurecr.io`- **Repositorio Git:** `https://github.com/semaxyD/proyectoCC_Multinube.git`

- **Kubernetes Version:** `v1.33.5`- **Resource Group:** `rg-k8s-azure`

- **Nodos:** 2x Standard_B2s- **Region:** `East US 2`

- **IP PÃºblica:** `20.15.66.143`

---

---

## ğŸš€ Paso 1: Configurar Azure CLI

## ğŸ”§ Problema 1: Pods en CrashLoopBackOff

### 1.1 Azure Cloud Shell 

### DiagnÃ³stico Inicial

1. Ir a [https://portal.azure.com](https://portal.azure.com)

```bash2. Click en el Ã­cono **Cloud Shell** (>_) en la barra superior

# Verificar estado de pods3. Seleccionar **Bash**

kubectl get pods -n microstore4. Esperar a que se inicialice

---

# Resultado:

# NAME                                   READY   STATUS             RESTARTS   AGE## â˜ï¸ Paso 2: Crear Resource Group

# users-deployment-xxxxx-xxxxx           0/1     CrashLoopBackOff   5          5m

# products-deployment-xxxxx-xxxxx        0/1     CrashLoopBackOff   5          5m```bash

# orders-deployment-xxxxx-xxxxx          0/1     CrashLoopBackOff   5          5m# Definir variables

# frontend-deployment-xxxxx-xxxxx        0/1     CrashLoopBackOff   5          5mRESOURCE_GROUP="rg-k8s-azure"

LOCATION="eastus2"

# Ver logs para identificar el problema

kubectl logs -n microstore users-deployment-xxxxx-xxxxx# Crear resource group

az group create \

# Error encontrado:  --name $RESOURCE_GROUP \

# KeyError: 'MYSQL_HOST'  --location $LOCATION

# El cÃ³digo busca MYSQL_HOST pero el secret tiene DB_HOST

```# Verificar

az group show --name $RESOURCE_GROUP --output table

### Causa RaÃ­z```



- El cÃ³digo de los microservicios usa variables de entorno con el patrÃ³n `MYSQL_*` ---

- El secret `database-secret` tenÃ­a keys con el patrÃ³n `DB_*` (DB_HOST, DB_USER, etc.)

- **Mismatch de nombres** causaba que los pods no pudieran leer las credenciales## ğŸ—„ï¸ Paso 3: Crear Azure Container Registry (ACR)



### SoluciÃ³n: Recrear Secret con Nombres Correctos### 3.1 Crear ACR



```bash```bash

# 1. Eliminar el secret incorrecto# Nombre Ãºnico del registry (debe ser Ãºnico globalmente)

kubectl delete secret database-secret -n microstoreACR_NAME="acrk8sazure$(date +%s)"

echo "ACR Name: $ACR_NAME"

# 2. Crear secret con las keys correctas (MYSQL_* en lugar de DB_*)

kubectl create secret generic database-secret -n microstore \# Crear ACR

  --from-literal=MYSQL_HOST=mysql-service \az acr create \

  --from-literal=MYSQL_USER=root \  --resource-group $RESOURCE_GROUP \

  --from-literal=MYSQL_PASSWORD=root \  --name $ACR_NAME \

  --from-literal=MYSQL_DB=microstore \  --sku Basic \

  --from-literal=MYSQL_PORT=3306  --location $LOCATION



# 3. Verificar que las keys sean correctas# Verificar

kubectl describe secret database-secret -n microstoreaz acr show --name $ACR_NAME --resource-group $RESOURCE_GROUP --output table

```

# Debe mostrar: MYSQL_HOST, MYSQL_USER, MYSQL_PASSWORD, MYSQL_DB, MYSQL_PORT

### 3.2 Guardar el nombre del ACR

# 4. Reiniciar deployments para que carguen el nuevo secret

kubectl rollout restart deployment users-deployment -n microstore```bash

kubectl rollout restart deployment products-deployment -n microstore# Guardar en variable de entorno (importante para pasos siguientes)

kubectl rollout restart deployment orders-deployment -n microstoreexport ACR_NAME="<tu-acr-name>"

kubectl rollout restart deployment frontend-deployment -n microstore# Ejemplo: export ACR_NAME="acrk8sazure1762621825"

```

# 5. Verificar que los pods estÃ©n Running

kubectl get pods -n microstore -w---

```

## â˜¸ï¸ Paso 4: Crear Cluster AKS

**Resultado:** Todos los pods transicionaron de `CrashLoopBackOff` a `Running 1/1` âœ…

### 4.1 Crear el cluster

---

```bash

## ğŸŒ Problema 2: Ingress No Funciona (404 Errors)# Nombre del cluster

AKS_CLUSTER="k8s-azure"

### DiagnÃ³stico

# Crear cluster AKS (tarda 5-10 minutos)

```bashaz aks create \

# Verificar Ingress  --resource-group $RESOURCE_GROUP \

kubectl get ingress -n microstore  --name $AKS_CLUSTER \

  --node-count 2 \

# Resultado: ADDRESS vacÃ­a, no hay IP asignada  --node-vm-size Standard_B2s \

# NAME               CLASS   HOSTS   ADDRESS   PORTS   AGE  --enable-managed-identity \

# frontend-ingress   <none>  *                 80      10m  --generate-ssh-keys \

# users-ingress      <none>  *                 80      10m  --location $LOCATION

# products-ingress   <none>  *                 80      10m

# orders-ingress     <none>  *                 80      10m# Verificar

```az aks show --resource-group $RESOURCE_GROUP --name $AKS_CLUSTER --output table

```

### Causa RaÃ­z

### 4.2 Conectar kubectl al cluster

- No habÃ­a **NGINX Ingress Controller** instalado en el cluster

- Los recursos Ingress no tenÃ­an `ingressClassName` especificado```bash

- Sin controlador, no se puede enrutar el trÃ¡fico externo# Obtener credenciales

az aks get-credentials \

### SoluciÃ³n Parte 1: Instalar NGINX Ingress Controller  --resource-group $RESOURCE_GROUP \

  --name $AKS_CLUSTER \

```bash  --overwrite-existing

# Instalar NGINX Ingress Controller para AKS

kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.8.1/deploy/static/provider/cloud/deploy.yaml# Verificar conexiÃ³n

kubectl get nodes

# Verificar instalaciÃ³n```

kubectl get pods -n ingress-nginx

**Salida esperada:**

# Esperar a que todos los pods estÃ©n Running```

kubectl wait --namespace ingress-nginx \NAME                                STATUS   ROLES   AGE   VERSION

  --for=condition=ready pod \aks-default-89644245-vmss000002     Ready    agent   5m    v1.33.5

  --selector=app.kubernetes.io/component=controller \aks-default-89644245-vmss000003     Ready    agent   5m    v1.33.5

  --timeout=120s```

```

### 4.3 Integrar ACR con AKS

### SoluciÃ³n Parte 2: Obtener IP Externa

```bash

```bash# Adjuntar ACR al cluster

# Ver servicio del Ingress Controller (esperar a que se asigne EXTERNAL-IP)az aks update \

kubectl get svc ingress-nginx-controller -n ingress-nginx --watch  --name $AKS_CLUSTER \

  --resource-group $RESOURCE_GROUP \

# Esto crea un Azure Load Balancer y asigna una IP pÃºblica  --attach-acr $ACR_NAME

# Puede tardar 2-3 minutos

# Verificar integraciÃ³n

# Una vez asignada, guardar la IPaz aks check-acr \

EXTERNAL_IP=$(kubectl get svc ingress-nginx-controller -n ingress-nginx -o jsonpath='{.status.loadBalancer.ingress[0].ip}')  --name $AKS_CLUSTER \

echo "IP Externa: $EXTERNAL_IP"  --resource-group $RESOURCE_GROUP \

  --acr ${ACR_NAME}.azurecr.io

# Resultado: 20.15.66.143```

```

---

### SoluciÃ³n Parte 3: Actualizar Ingress con ingressClassName

## ğŸ“¦ Paso 5: Clonar Repositorio y Construir ImÃ¡genes

```bash

# Agregar ingressClassName: nginx a todos los Ingress### 5.1 Clonar el repositorio

kubectl patch ingress frontend-ingress -n microstore \

  --type='json' \```bash

  -p='[{"op": "add", "path": "/spec/ingressClassName", "value": "nginx"}]'# En Cloud Shell

cd ~

kubectl patch ingress users-ingress -n microstore \git clone https://github.com/Makhai412/proyectoFinalCloudComputing.git

  --type='json' \cd proyectoFinalCloudComputing/microProyecto2_CloudComputing

  -p='[{"op": "add", "path": "/spec/ingressClassName", "value": "nginx"}]'```



kubectl patch ingress products-ingress -n microstore \### 5.2 Construir imÃ¡genes con ACR Build

  --type='json' \

  -p='[{"op": "add", "path": "/spec/ingressClassName", "value": "nginx"}]'**Nota:** Azure Cloud Shell no tiene Docker daemon, por eso usamos ACR Build



kubectl patch ingress orders-ingress -n microstore \```bash

  --type='json' \# Construir imagen de usuarios

  -p='[{"op": "add", "path": "/spec/ingressClassName", "value": "nginx"}]'az acr build \

  --registry $ACR_NAME \

# Verificar  --image microstore-users:latest \

kubectl get ingress -n microstore  --file microUsers/Dockerfile \

```  ./microUsers



**Resultado esperado:**# Construir imagen de productos

```az acr build \

NAME               CLASS   HOSTS   ADDRESS         PORTS   AGE  --registry $ACR_NAME \

frontend-ingress   nginx   *       20.15.66.143    80      15m  --image microstore-products:latest \

orders-ingress     nginx   *       20.15.66.143    80      15m  --file microProducts/Dockerfile \

products-ingress   nginx   *       20.15.66.143    80      15m  ./microProducts

users-ingress      nginx   *       20.15.66.143    80      15m

```# Construir imagen de Ã³rdenes

az acr build \

âœ… **Ingress funcionando con IP pÃºblica asignada**  --registry $ACR_NAME \

  --image microstore-orders:latest \

---  --file microOrders/Dockerfile \

  ./microOrders

## ğŸ”„ Problema 3: Error 503 DespuÃ©s de Reiniciar Cluster

# Construir imagen del frontend

### DiagnÃ³sticoaz acr build \

  --registry $ACR_NAME \

DespuÃ©s de detener y reiniciar el cluster AKS:  --image microstore-frontend:latest \

  --file frontend/Dockerfile \

```bash  ./frontend

# Acceder a la aplicaciÃ³n```

curl http://20.15.66.143/api/users/

### 5.3 Verificar imÃ¡genes

# Error: 503 Service Temporarily Unavailable

``````bash

# Listar imÃ¡genes en ACR

```javascriptaz acr repository list --name $ACR_NAME --output table

// En el navegador (Console)

GET http://20.15.66.143/api/users/ 503# Ver tags de una imagen especÃ­fica

SyntaxError: Unexpected token '<', "<html><h"... is not valid JSONaz acr repository show-tags --name $ACR_NAME --repository microstore-users --output table

``````



### Causa RaÃ­z---



- Los pods de los microservicios no estÃ¡n listos## ğŸ”§ Paso 6: Actualizar Manifiestos de Kubernetes

- El Ingress Controller responde pero no puede enrutar al backend

- Es necesario reiniciar sistemÃ¡ticamente todos los deployments### 6.1 Actualizar referencias al registry



### SoluciÃ³n: Script de Reinicio Automatizado```bash

# Reemplazar placeholder con nombre real del ACR

**Crear archivo `restart-aks.sh`:**find k8s -name "*.yaml" -type f -exec sed -i "s|<TU_REGISTRY>|${ACR_NAME}.azurecr.io|g" {} +



```bash# Verificar cambios

#!/bin/bashgrep -r "azurecr.io" k8s/*/deployment.yaml

```

echo "ğŸ”„ Reiniciando servicios en AKS..."

---

# 1. Reiniciar Ingress Controller

echo "ğŸ“¡ Reiniciando Ingress Controller..."## ğŸ—„ï¸ Paso 7: Desplegar MySQL

kubectl rollout restart deployment ingress-nginx-controller -n ingress-nginx

kubectl rollout status deployment ingress-nginx-controller -n ingress-nginx --timeout=5m### 7.1 Crear namespace



# 2. Reiniciar todos los microservicios```bash

echo "ğŸš€ Reiniciando microservicios..."kubectl create namespace microstore

kubectl rollout restart deployment users-deployment -n microstore```

kubectl rollout restart deployment products-deployment -n microstore

kubectl rollout restart deployment orders-deployment -n microstore### 7.2 Crear secret con credenciales correctas

kubectl rollout restart deployment frontend-deployment -n microstore

```bash

# 3. Esperar a que todos estÃ©n listos# IMPORTANTE: Usar MYSQL_* en lugar de DB_*

echo "â³ Esperando a que los pods estÃ©n listos..."kubectl create secret generic database-secret -n microstore \

kubectl wait --for=condition=ready pod -l app=users -n microstore --timeout=5m  --from-literal=MYSQL_HOST=mysql-service \

kubectl wait --for=condition=ready pod -l app=products -n microstore --timeout=5m  --from-literal=MYSQL_USER=root \

kubectl wait --for=condition=ready pod -l app=orders -n microstore --timeout=5m  --from-literal=MYSQL_PASSWORD=root \

kubectl wait --for=condition=ready pod -l app=frontend -n microstore --timeout=5m  --from-literal=MYSQL_DB=microstore \

  --from-literal=MYSQL_PORT=3306

# 4. Verificar IP externa

EXTERNAL_IP=$(kubectl get svc ingress-nginx-controller -n ingress-nginx -o jsonpath='{.status.loadBalancer.ingress[0].ip}')# Verificar

echo "âœ… IP Externa: $EXTERNAL_IP"kubectl describe secret database-secret -n microstore

```

# 5. Probar endpoints

echo "ğŸ§ª Probando endpoints..."### 7.3 Desplegar MySQL

curl -s http://$EXTERNAL_IP/api/users/ | head -n 1

curl -s http://$EXTERNAL_IP/api/products/ | head -n 1```bash

# ConfigMap de inicializaciÃ³n

echo "âœ… Reinicio completado"kubectl apply -f k8s/mysql/mysql-initdb-configmap.yaml

```

# Secret de MySQL

**Uso:**kubectl apply -f k8s/mysql/secret.yaml



```bash# Servicios

# Hacer ejecutablekubectl apply -f k8s/mysql/headless-service.yaml

chmod +x restart-aks.shkubectl apply -f k8s/mysql/service.yaml



# Ejecutar# StatefulSet

./restart-aks.shkubectl apply -f k8s/mysql/statefulset.yaml

```

# Verificar

**Resultado:** AplicaciÃ³n accesible nuevamente en `http://20.15.66.143/` âœ…kubectl get pods -n microstore -w

# Esperar hasta que mysql-0 estÃ© Running 1/1

---```



## ğŸ› Problema 4: ComunicaciÃ³n Entre Microservicios### 7.4 Poblar base de datos (Opcional)



### DiagnÃ³stico```bash

# Conectarse a MySQL

El microservicio de **Orders** necesita comunicarse con **Products** para validar los productos al crear una orden.kubectl exec -it mysql-0 -n microstore -- mysql -u root microstore



```bash# Insertar datos de prueba

# Error en logs del microservicio ordersINSERT INTO users (name, email, username, password) 

kubectl logs -n microstore orders-deployment-xxxxx-xxxxxVALUES ('Admin User', 'admin@microstore.com', 'admin', 

'$2b$12$LQv3c1yqBWVHxkd0LHAkCOYz6TtxMQJqhN8/LewY5GyYAZhXXXXXX');

# requests.exceptions.ConnectionError: Failed to establish connection to products service

```INSERT INTO products (name, description, price, stock) 

VALUES ('Laptop Dell XPS 15', 'High performance laptop', 1500.00, 10),

### Causa RaÃ­z       ('Mouse Logitech MX', 'Wireless mouse', 99.99, 50),

       ('Teclado MecÃ¡nico', 'RGB keyboard', 149.99, 30);

- El cÃ³digo tenÃ­a hardcodeado `http://products:5003` (nombre de pod en lugar de servicio)

- DebÃ­a usar el nombre del servicio: `products-service`-- Salir

EXIT;

### SoluciÃ³n: Actualizar CÃ³digo y Deployment```



**1. Modificar `microOrders/orders/controllers/order_controller.py`:**---



```python## ğŸš€ Paso 8: Desplegar Microservicios

import os  # Agregar import

### 8.1 ConfigMap comÃºn

# Agregar al inicio del archivo

PRODUCTS_SERVICE_URL = os.getenv('PRODUCTS_SERVICE_URL', 'http://localhost:5003')```bash

kubectl apply -f k8s/common/configmap.yaml

# Cambiar las llamadas hardcodeadas```

# ANTES:

# resp = requests.get(f'http://products:5003/api/products/{product_id}')### 8.2 Microservicio de Usuarios



# DESPUÃ‰S:```bash

resp = requests.get(f'{PRODUCTS_SERVICE_URL}/api/products/{product_id}')kubectl apply -f k8s/users/deployment.yaml

```kubectl apply -f k8s/users/service.yaml

kubectl apply -f k8s/users/ingress.yaml

**2. Actualizar `k8s/orders/deployment.yaml`:**

# Verificar

```yamlkubectl get pods -n microstore -l app=users

env:```

  - name: PRODUCTS_SERVICE_URL

    value: "http://products-service"  # Agregar esta variable### 8.3 Microservicio de Productos

  - name: MYSQL_HOST

    valueFrom:```bash

      secretKeyRef:kubectl apply -f k8s/products/deployment.yaml

        name: database-secretkubectl apply -f k8s/products/service.yaml

        key: MYSQL_HOSTkubectl apply -f k8s/products/ingress.yaml

  # ... resto de variables

```# Verificar

kubectl get pods -n microstore -l app=products

**3. Reconstruir imagen y redesplegar:**```



```bash### 8.4 Microservicio de Ã“rdenes

# En Azure Cloud Shell

cd ~/proyectoFinalCloudComputing/microProyecto2_CloudComputing```bash

kubectl apply -f k8s/orders/deployment.yaml

# Reconstruir imagen con ACR Buildkubectl apply -f k8s/orders/service.yaml

az acr build \kubectl apply -f k8s/orders/ingress.yaml

  --registry acrk8sazure1762621825 \

  --image microstore-orders:latest \# Verificar

  --file microOrders/Dockerfile \kubectl get pods -n microstore -l app=orders

  ./microOrders```



# Aplicar cambios al deployment### 8.5 Frontend

kubectl apply -f k8s/orders/deployment.yaml

```bash

# Reiniciar deploymentkubectl apply -f k8s/frontend/deployment.yaml

kubectl rollout restart deployment orders-deployment -n microstorekubectl apply -f k8s/frontend/service.yaml

kubectl apply -f k8s/frontend/ingress.yaml

# Verificar

kubectl get pods -n microstore -l app=orders# Verificar

```kubectl get pods -n microstore -l app=frontend

```

**Resultado:** Orders puede comunicarse con Products a travÃ©s del servicio âœ…

### 8.6 Verificar todos los pods

---

```bash

## ğŸ¯ IntegraciÃ³n con Rancherkubectl get pods -n microstore



### Contexto# Todos deben estar en estado Running 1/1

```

Se requerÃ­a gestionar centralmente ambos clusters (local Minikube y Azure AKS) desde Rancher.

---

- **Rancher Server:** `https://52.225.216.248`

## ğŸŒ Paso 9: Configurar Ingress Controller

### Pasos de IntegraciÃ³n

### 9.1 Instalar NGINX Ingress Controller

**1. Importar cluster en Rancher UI:**

```bash

```# Instalar en AKS (crea un Load Balancer de Azure)

1. Acceder a Rancher: https://52.225.216.248kubectl apply -f https://raw.githubusercontent.com/kubernetes/ingress-nginx/controller-v1.8.1/deploy/static/provider/cloud/deploy.yaml

2. Navegar a: â˜° â†’ Cluster Management

3. Click en: Import Existing# Verificar instalaciÃ³n

4. Nombre: k8s-azurekubectl get pods -n ingress-nginx

5. Copiar el comando kubectl apply que aparece

```# Esperar a que todos los pods estÃ©n Running

kubectl wait --namespace ingress-nginx \

**2. Ejecutar en Azure Cloud Shell:**  --for=condition=ready pod \

  --selector=app.kubernetes.io/component=controller \

```bash  --timeout=120s

# Pegar el comando copiado de Rancher```

kubectl apply -f https://52.225.216.248/v3/import/xxxxxxxxxxxxxx.yaml

### 9.2 Obtener IP Externa del Load Balancer

# Verificar cattle-system

kubectl get pods -n cattle-system```bash

# Esperar a que se asigne IP externa (puede tardar 2-3 minutos)

# Esperar a que los agentes estÃ©n Runningkubectl get svc ingress-nginx-controller -n ingress-nginx --watch

kubectl wait --for=condition=ready pod -n cattle-system --all --timeout=5m

```# Una vez asignada, guardar la IP

EXTERNAL_IP=$(kubectl get svc ingress-nginx-controller -n ingress-nginx -o jsonpath='{.status.loadBalancer.ingress[0].ip}')

**3. Verificar en Rancher UI:**echo "IP Externa: $EXTERNAL_IP"

```

- El cluster `k8s-azure` debe aparecer en la lista

- Estado: **Active** âœ…### 9.3 Actualizar Ingress con ingressClassName

- Se puede ver namespace `microstore` con todos los recursos

```bash

**Resultado:** Cluster AKS gestionado desde Rancher âœ…# Agregar ingressClassName a todos los Ingress

kubectl patch ingress frontend-ingress -n microstore --type='json' -p='[{"op": "add", "path": "/spec/ingressClassName", "value": "nginx"}]'

---

kubectl patch ingress users-ingress -n microstore --type='json' -p='[{"op": "add", "path": "/spec/ingressClassName", "value": "nginx"}]'

## ğŸ”„ Reiniciar el Cluster

kubectl patch ingress products-ingress -n microstore --type='json' -p='[{"op": "add", "path": "/spec/ingressClassName", "value": "nginx"}]'

### CuÃ¡ndo Usar

kubectl patch ingress orders-ingress -n microstore --type='json' -p='[{"op": "add", "path": "/spec/ingressClassName", "value": "nginx"}]'

- DespuÃ©s de detener el cluster con `az aks stop`

- Al dÃ­a siguiente de dejarlo sin uso# Verificar

- Cuando los pods no respondenkubectl get ingress -n microstore

```

### Procedimiento Completo

**Salida esperada:**

```bash```

# 1. Iniciar el cluster (si estÃ¡ detenido)NAME               CLASS   HOSTS   ADDRESS         PORTS   AGE

az aks start --name k8s-azure --resource-group rg-k8s-azurefrontend-ingress   nginx   *       20.15.66.143    80      10m

orders-ingress     nginx   *       20.15.66.143    80      10m

# 2. Reconectar kubectlproducts-ingress   nginx   *       20.15.66.143    80      10m

az aks get-credentials \users-ingress      nginx   *       20.15.66.143    80      10m

  --resource-group rg-k8s-azure \```

  --name k8s-azure \

  --overwrite-existing---



# 3. Verificar que los nodos estÃ©n listos## âœ… Paso 10: Verificar el Despliegue

kubectl get nodes

### 10.1 Ver todos los recursos

# 4. Ejecutar script de reinicio

./scripts/restart-aks.sh```bash

kubectl get all -n microstore

# 5. Verificar aplicaciÃ³n```

curl http://20.15.66.143/api/users/

```### 10.2 Probar endpoints



---```bash

# Probar usuarios

## âœ… VerificaciÃ³n Finalcurl http://$EXTERNAL_IP/api/users/



### Estado de Recursos# Probar productos

curl http://$EXTERNAL_IP/api/products/

```bash

# Ver todos los recursos# Probar Ã³rdenes

kubectl get all -n microstorecurl http://$EXTERNAL_IP/api/orders/



# Resultado esperado:# Probar frontend

# NAME                                      READY   STATUS    RESTARTS   AGEcurl http://$EXTERNAL_IP/

# pod/frontend-deployment-xxxxx-xxxxx       1/1     Running   0          10m```

# pod/mysql-0                               1/1     Running   0          20m

# pod/orders-deployment-xxxxx-xxxxx         1/1     Running   0          10m### 10.3 Acceder desde el navegador

# pod/products-deployment-xxxxx-xxxxx       1/1     Running   0          10m

# pod/users-deployment-xxxxx-xxxxx          1/1     Running   0          10m```bash

```echo "ğŸŒ AplicaciÃ³n disponible en: http://$EXTERNAL_IP/"

```

### Probar Endpoints

Abre tu navegador y accede a la IP mostrada.

```bash

# Usuarios---

curl http://20.15.66.143/api/users/

# Debe retornar JSON con lista de usuarios## ğŸ¯ Paso 11: IntegraciÃ³n con Rancher (Opcional)



# Productos### 11.1 Requisitos

curl http://20.15.66.143/api/products/- Rancher Server desplegado (ejemplo: `https://52.225.216.248`)

# Debe retornar JSON con lista de productos- Acceso de administrador a Rancher



# Frontend### 11.2 Importar cluster a Rancher

curl http://20.15.66.143/

# Debe retornar HTML del dashboard1. **En Rancher UI:**

```   - Navegar a **â˜° â†’ Cluster Management**

   - Click en **Import Existing**

### Acceso Web   - Nombre: `k8s-azure`

   - Copiar el comando `kubectl apply`

```

ğŸŒ AplicaciÃ³n: http://20.15.66.143/2. **En Azure Cloud Shell:**

ğŸ“Š Usuarios: http://20.15.66.143/api/users/   ```bash

ğŸ“¦ Productos: http://20.15.66.143/api/products/   # Pegar el comando copiado de Rancher

ğŸ›’ Ã“rdenes: http://20.15.66.143/api/orders/   kubectl apply -f https://52.225.216.248/v3/import/xxxxx.yaml

```   

   # Verificar cattle-system

---   kubectl get pods -n cattle-system

   ```

## ğŸ› ï¸ Comandos Ãštiles para Troubleshooting

3. **Esperar 2-5 minutos** hasta que aparezca como **Active** en Rancher

### Ver Logs

### 11.3 Verificar integraciÃ³n

```bash

# Logs en tiempo real de un microservicioEn Rancher UI:

kubectl logs -n microstore -l app=users -f --tail=50- El cluster `k8s-azure` debe aparecer en la lista

- Estado: **Active** âœ…

# Logs de un pod especÃ­fico- Puedes ver todos los recursos del namespace `microstore`

kubectl logs -n microstore <pod-name> --tail=100

---

# Logs de pod anterior (si crasheÃ³)

kubectl logs -n microstore <pod-name> --previous## ğŸ“Š Monitoreo y Logs

```

### Ver logs de un microservicio

### Reiniciar Deployments

```bash

```bash# Ver logs en tiempo real

# Reiniciar un deployment especÃ­ficokubectl logs -n microstore -l app=users -f --tail=50

kubectl rollout restart deployment users-deployment -n microstore

# Ver logs de un pod especÃ­fico

# Ver estado del rolloutkubectl logs -n microstore <pod-name> --tail=100

kubectl rollout status deployment users-deployment -n microstore```



# Ver historial de revisiones### Dashboard de Kubernetes (Azure Portal)

kubectl rollout history deployment users-deployment -n microstore

```1. Ir a [portal.azure.com](https://portal.azure.com)

2. Buscar tu cluster AKS: `k8s-azure`

### Describir Recursos3. En el menÃº lateral: **Kubernetes resources â†’ Workloads**

4. Ver pods, deployments, services, etc.

```bash

# Describir pod (ver eventos y errores)### MÃ©tricas con kubectl

kubectl describe pod -n microstore <pod-name>

```bash

# Describir Ingress# Top de nodos

kubectl describe ingress frontend-ingress -n microstorekubectl top nodes



# Describir secret# Top de pods

kubectl describe secret database-secret -n microstorekubectl top pods -n microstore

``````



### Shell en Pod---



```bash## ğŸ”„ Actualizar la AplicaciÃ³n

# Abrir shell en un pod

kubectl exec -it -n microstore <pod-name> -- /bin/bash### Actualizar cÃ³digo y redesplegar



# Ejecutar comando en pod```bash

kubectl exec -n microstore <pod-name> -- env | grep MYSQL# 1. Hacer cambios en el cÃ³digo local

```# 2. Reconstruir la imagen

az acr build \

### Verificar Variables de Entorno  --registry $ACR_NAME \

  --image microstore-users:latest \

```bash  ./microUsers

# Ver variables de un deployment

kubectl get deployment users-deployment -n microstore -o yaml | grep -A 10 env:# 3. Reiniciar deployment (pull nueva imagen)

kubectl rollout restart deployment users-deployment -n microstore

# Ver secret decodificado

kubectl get secret database-secret -n microstore -o jsonpath='{.data.MYSQL_HOST}' | base64 -d# 4. Monitorear rollout

```kubectl rollout status deployment users-deployment -n microstore



---# 5. Verificar

kubectl get pods -n microstore -l app=users

## ğŸ’° OptimizaciÃ³n de Costos```



### Detener el Cluster (Ahorrar ~$30/mes)### Rollback a versiÃ³n anterior



```bash```bash

# Detener cluster (mantiene configuraciÃ³n y datos)# Ver historial

az aks stop --name k8s-azure --resource-group rg-k8s-azurekubectl rollout history deployment users-deployment -n microstore



# El Load Balancer y ACR siguen cobrando (~$10/mes)# Rollback

```kubectl rollout undo deployment users-deployment -n microstore



### Reiniciar Cluster# Rollback a revisiÃ³n especÃ­fica

kubectl rollout undo deployment users-deployment -n microstore --to-revision=2

```bash```

# Iniciar cluster

az aks start --name k8s-azure --resource-group rg-k8s-azure---



# Reconectar kubectl## ğŸ” Troubleshooting

az aks get-credentials --resource-group rg-k8s-azure --name k8s-azure

### Problema: Pods en CrashLoopBackOff

# Ejecutar script de reinicio

./scripts/restart-aks.sh```bash

```# Ver logs

kubectl logs -n microstore <pod-name> --previous

### EstimaciÃ³n de Costos

# Describir pod

| Recurso | Costo/Mes | Notas |kubectl describe pod -n microstore <pod-name>

|---------|-----------|-------|

| AKS Control Plane | Gratis | Incluido |# Verificar variables de entorno

| 2x Standard_B2s Nodes | ~$30 | Se puede detener |kubectl exec -n microstore <pod-name> -- env | grep MYSQL

| Load Balancer | ~$5 | Cobra incluso detenido |```

| ACR Basic | ~$5 | Cobra incluso detenido |

| Public IP | ~$3 | Cobra incluso detenido |### Problema: No puedo acceder a la aplicaciÃ³n

| **Total con cluster activo** | **~$43** | |

| **Total con cluster detenido** | **~$13** | Solo infraestructura |```bash

# Verificar Load Balancer

---kubectl get svc -n ingress-nginx



## ğŸ“ Resumen de Soluciones Implementadas# Verificar Ingress

kubectl get ingress -n microstore

| Problema | Causa RaÃ­z | SoluciÃ³n | Resultado |kubectl describe ingress frontend-ingress -n microstore

|----------|-----------|----------|-----------|

| **CrashLoopBackOff** | Mismatch de nombres de variables (DB_* vs MYSQL_*) | Recrear secret con keys correctas | Pods Running âœ… |# Verificar logs del Ingress Controller

| **Ingress 404** | No habÃ­a Ingress Controller instalado | Instalar NGINX Ingress + agregar ingressClassName | IP pÃºblica asignada âœ… |kubectl logs -n ingress-nginx -l app.kubernetes.io/component=controller --tail=50

| **Error 503 despuÃ©s de reinicio** | Pods no listos al reiniciar cluster | Script de reinicio automatizado | AplicaciÃ³n disponible âœ… |```

| **Orders no comunica con Products** | URL hardcodeada incorrecta | Variable de entorno PRODUCTS_SERVICE_URL | ComunicaciÃ³n exitosa âœ… |

| **GestiÃ³n centralizada** | Clusters aislados | IntegraciÃ³n con Rancher | Ambos clusters en Rancher âœ… |### Problema: "Unknown database 'myflaskapp'"



---**Causa:** Secret tiene nombre de base de datos incorrecto



## ğŸ“š Referencias**SoluciÃ³n:**

```bash

- [NGINX Ingress Controller Documentation](https://kubernetes.github.io/ingress-nginx/)# Eliminar secret

- [Azure AKS Troubleshooting](https://docs.microsoft.com/en-us/azure/aks/troubleshooting)kubectl delete secret database-secret -n microstore

- [Kubernetes Secrets](https://kubernetes.io/docs/concepts/configuration/secret/)

- [Rancher Documentation](https://rancher.com/docs/)# Recrear con datos correctos

kubectl create secret generic database-secret -n microstore \

---  --from-literal=MYSQL_HOST=mysql-service \

  --from-literal=MYSQL_USER=root \

**Autor:** Equipo de Desarrollo Cloud Computing    --from-literal=MYSQL_PASSWORD=root \

**Ãšltima actualizaciÃ³n:** Noviembre 10, 2025    --from-literal=MYSQL_DB=microstore \

**VersiÃ³n:** 2.0 (ImplementaciÃ³n Real)    --from-literal=MYSQL_PORT=3306

**IP PÃºblica de la AplicaciÃ³n:** http://20.15.66.143/

# Reiniciar deployments
kubectl rollout restart deployment users-deployment -n microstore
kubectl rollout restart deployment products-deployment -n microstore
kubectl rollout restart deployment orders-deployment -n microstore
```

### Problema: ImÃ¡genes no se descargan de ACR

```bash
# Verificar integraciÃ³n ACR-AKS
az aks check-acr \
  --name $AKS_CLUSTER \
  --resource-group $RESOURCE_GROUP \
  --acr ${ACR_NAME}.azurecr.io

# Si falla, re-adjuntar
az aks update \
  --name $AKS_CLUSTER \
  --resource-group $RESOURCE_GROUP \
  --attach-acr $ACR_NAME
```

---

## ğŸ’° EstimaciÃ³n de Costos (Azure for Students)

### Recursos Utilizados

| Recurso | SKU/TamaÃ±o | Costo Aprox. |
|---------|-----------|--------------|
| AKS Control Plane | Managed | **Gratis** |
| VM Nodes (2x) | Standard_B2s | ~$30/mes |
| Load Balancer | Basic | ~$5/mes |
| ACR | Basic | ~$5/mes |
| Public IP | Standard | ~$3/mes |
| **Total Estimado** | | **~$43/mes** |

**Nota:** Con Azure for Students tienes $100 de crÃ©dito por 12 meses.

### OptimizaciÃ³n de Costos

```bash
# Detener el cluster (mantiene configuraciÃ³n)
az aks stop --name $AKS_CLUSTER --resource-group $RESOURCE_GROUP

# Iniciar nuevamente
az aks start --name $AKS_CLUSTER --resource-group $RESOURCE_GROUP

# Escalar a 0 nodos (ahorra costo de VMs pero Load Balancer sigue activo)
az aks scale \
  --name $AKS_CLUSTER \
  --resource-group $RESOURCE_GROUP \
  --node-count 0
```

---

## ğŸ›‘ Limpieza de Recursos

### Eliminar solo el namespace

```bash
kubectl delete namespace microstore
```

### Eliminar el cluster AKS

```bash
az aks delete \
  --name $AKS_CLUSTER \
  --resource-group $RESOURCE_GROUP \
  --yes --no-wait
```

### Eliminar todo el Resource Group

```bash
# âš ï¸ CUIDADO: Esto elimina TODO
az group delete \
  --name $RESOURCE_GROUP \
  --yes --no-wait
```

---

## ğŸ“Š Arquitectura del Despliegue en Azure

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    AZURE CLOUD                             â”‚
â”‚                                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚         Resource Group: rg-k8s-azure                 â”‚ â”‚
â”‚  â”‚         Region: East US 2                            â”‚ â”‚
â”‚  â”‚                                                      â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚
â”‚  â”‚  â”‚  Azure Container Registry (ACR)                â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  acrk8sazure1762621825.azurecr.io             â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  â”‚ Images:                                  â”‚ â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  â”‚ - microstore-users:latest                â”‚ â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  â”‚ - microstore-products:latest             â”‚ â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  â”‚ - microstore-orders:latest               â”‚ â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  â”‚ - microstore-frontend:latest             â”‚ â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚
â”‚  â”‚                                                      â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚
â”‚  â”‚  â”‚  AKS Cluster: k8s-azure                        â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  Kubernetes: v1.33.5                           â”‚ â”‚ â”‚
â”‚  â”‚  â”‚                                                â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  â”‚  Node Pool (Standard_B2s x2)             â”‚ â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  â”‚                                          â”‚ â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  â”‚  Namespace: microstore                   â”‚ â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  â”‚  â”‚  MySQL StatefulSet                 â”‚ â”‚ â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  â”‚  â”‚  - mysql-0 (Azure Managed Disk)    â”‚ â”‚ â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  â”‚                                          â”‚ â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  â”‚  â”‚  Microservices (2 replicas each)   â”‚ â”‚ â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  â”‚  â”‚  - users-deployment                â”‚ â”‚ â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  â”‚  â”‚  - products-deployment             â”‚ â”‚ â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  â”‚  â”‚  - orders-deployment               â”‚ â”‚ â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  â”‚  â”‚  - frontend-deployment             â”‚ â”‚ â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  â”‚                                          â”‚ â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  â”‚  Namespace: ingress-nginx                â”‚ â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  â”‚  â”‚  NGINX Ingress Controller          â”‚ â”‚ â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚
â”‚  â”‚                                                      â”‚ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚ â”‚
â”‚  â”‚  â”‚  Azure Load Balancer                           â”‚ â”‚ â”‚
â”‚  â”‚  â”‚  Public IP: 20.15.66.143                       â”‚ â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â–²
                    â”‚
         Internet (http://20.15.66.143/)
```

---

## ğŸ” Credenciales

### MySQL en AKS
- **Host:** `mysql-service.microstore.svc.cluster.local`
- **Puerto:** `3306`
- **Usuario:** `root`
- **ContraseÃ±a:** `root`
- **Base de datos:** `microstore`

### Azure Container Registry
- **Registry:** `<ACR_NAME>.azurecr.io`
- **AutenticaciÃ³n:** Managed Identity (automÃ¡tica desde AKS)

---

## ğŸ“ Comandos de Referencia RÃ¡pida

```bash
# Verificar estado general
kubectl get all -n microstore

# Ver logs de todos los pods de un servicio
kubectl logs -n microstore -l app=users --tail=50

# Reiniciar un deployment
kubectl rollout restart deployment <name> -n microstore

# Escalar deployment
kubectl scale deployment users-deployment -n microstore --replicas=3

# Ver eventos
kubectl get events -n microstore --sort-by='.lastTimestamp'

# Shell en un pod
kubectl exec -it -n microstore <pod-name> -- /bin/bash

# Ver configuraciÃ³n de un recurso
kubectl get deployment users-deployment -n microstore -o yaml

# Aplicar cambios
kubectl apply -f k8s/users/deployment.yaml

# Ver costos (en portal)
az consumption usage list --output table
```

---

## ğŸ“š Referencias

- [Azure Kubernetes Service (AKS)](https://docs.microsoft.com/azure/aks/)
- [Azure Container Registry](https://docs.microsoft.com/azure/container-registry/)
- [NGINX Ingress Controller](https://kubernetes.github.io/ingress-nginx/)
- [kubectl Cheat Sheet](https://kubernetes.io/docs/reference/kubectl/cheatsheet/)

---

**Autor:** Equipo de Desarrollo Cloud Computing  
**Ãšltima actualizaciÃ³n:** Noviembre 8, 2025  
**VersiÃ³n:** 1.0  
**IP PÃºblica de la AplicaciÃ³n:** http://20.15.66.143/
